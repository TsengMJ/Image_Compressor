{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import h5py                                                                                                                                                                                   \n",
    "import numpy as np\n",
    "\n",
    "from keras import applications, optimizers\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(weights_path=None):\n",
    "    # number of possible label values\n",
    "    nb_classes = 6\n",
    "\n",
    "    # Initialising the CNN\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1 - Convolution\n",
    "    model.add(Conv2D(32,(4,4), padding='same', activation='relu',input_shape=(64, 64,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 2nd Convolution layer\n",
    "    model.add(Conv2D(64,(4,4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # 3rd Convolution layer\n",
    "    model.add(Conv2D(128,(2,2), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flattening\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "max_YCrCb = np.array([235,173,127],np.uint8)\n",
    "\n",
    "## Return grayscale image with white pixels are skin areas\n",
    "def getSkin(img):\n",
    "    # Get pointer to video frames from primary device\n",
    "    imageYCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    skinRegionYCrCb = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "#     skin = cv2.bitwise_and(img, img, mask = skinRegionYCrCb)\n",
    "\n",
    "    return skinRegionYCrCb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    os.chdir(path)\n",
    "    files = os.listdir()\n",
    "\n",
    "    for file in files:\n",
    "        img = cv2.imread(file)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        img = getSkin(img)/255.0\n",
    "        \n",
    "        label = file.split(\"_\")[0]\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    lenth = len(data)\n",
    "    data = np.asarray(data)\n",
    "    data = np.reshape(data, (lenth,64,64,1))\n",
    "    labels = np_utils.to_categorical(labels,6)\n",
    "    \n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = my_model()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VGG19():\n",
    "    model_tmp = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (224, 224, 3))\n",
    "    \n",
    "    # Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "#     for layer in model_tmp.layers[:5]:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "    #Adding custom Layers \n",
    "    x = model_tmp.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(6, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(input = model_tmp.input, output = predictions)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_generator():\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "#         brightness_range=[0.5,1.0],\n",
    "        horizontal_flip=True)\n",
    "    \n",
    "    return datagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Loading dataset\n",
      "[*] Spliting dataset\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 1s 1ms/step - loss: 1.3656 - categorical_accuracy: 0.4395 - val_loss: 0.7039 - val_categorical_accuracy: 0.7794\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 297us/step - loss: 0.5004 - categorical_accuracy: 0.8186 - val_loss: 0.6710 - val_categorical_accuracy: 0.7647\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 302us/step - loss: 0.3021 - categorical_accuracy: 0.8856 - val_loss: 0.3504 - val_categorical_accuracy: 0.8824\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 306us/step - loss: 0.1717 - categorical_accuracy: 0.9314 - val_loss: 0.2291 - val_categorical_accuracy: 0.9412\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 281us/step - loss: 0.0793 - categorical_accuracy: 0.9771 - val_loss: 0.1897 - val_categorical_accuracy: 0.9265\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 297us/step - loss: 0.0830 - categorical_accuracy: 0.9739 - val_loss: 0.3162 - val_categorical_accuracy: 0.9265\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 285us/step - loss: 0.0360 - categorical_accuracy: 0.9869 - val_loss: 0.1909 - val_categorical_accuracy: 0.9265\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 288us/step - loss: 0.0291 - categorical_accuracy: 0.9935 - val_loss: 0.1808 - val_categorical_accuracy: 0.9706\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 293us/step - loss: 0.0065 - categorical_accuracy: 1.0000 - val_loss: 0.2781 - val_categorical_accuracy: 0.9265\n",
      "Train on 612 samples, validate on 68 samples\n",
      "Epoch 1/1\n",
      "612/612 [==============================] - 0s 318us/step - loss: 0.0048 - categorical_accuracy: 1.0000 - val_loss: 0.1584 - val_categorical_accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "## DATASET FOLDER PATH\n",
    "PATH = \"/home/mj/HardDisk/Hand_Pose_Recognition/Dataset\"\n",
    "epochs = 1\n",
    "\n",
    "## Loading dataset\n",
    "print(\"[*] Loading dataset\")\n",
    "data, labels = load_data(PATH)\n",
    "\n",
    "## Spliting dataset\n",
    "print(\"[*] Spliting dataset\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=0.9, test_size=0.1, random_state=42)\n",
    "\n",
    "## load the model\n",
    "model = get_model()\n",
    "# model = get_VGG19()\n",
    "\n",
    "## Setting Image Augmentation\n",
    "datagen = get_data_generator()\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "for i in range(10):\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))\n",
    "    model.save_weights('../model/test_model_{}.h5'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 202us/step\n",
      "Test loss: 0.28934217000599294\n",
      "Test accuracy: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
