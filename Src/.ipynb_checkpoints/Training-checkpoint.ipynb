{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import h5py                                                                                                                                                                                   \n",
    "import numpy as np\n",
    "\n",
    "%run Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1227 06:21:14.924107 140152891025152 deprecation.py:506] From /home/mj/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 64, 64, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   36928       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 64)   0           batch_normalization_3[0][0]      \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   36928       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 64)   36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 64)   0           batch_normalization_11[0][0]     \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 64, 64, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 64)   0           batch_normalization_17[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   36928       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 64, 64)   0           batch_normalization_21[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 64, 64)   0           batch_normalization_23[0][0]     \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 64, 64)   0           batch_normalization_25[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 64, 64)   36928       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 64, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 64, 64, 64)   0           batch_normalization_27[0][0]     \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 64, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 64, 64, 64)   0           batch_normalization_29[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 64)   36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 64, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 64, 64, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 64)   36928       re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 64, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 64, 64, 64)   0           batch_normalization_31[0][0]     \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 64, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 64, 64, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 3)    1731        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Tanh (TensorFlowOpL [(None, 64, 64, 3)]  0           conv2d_34[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,230,595\n",
      "Trainable params: 1,226,371\n",
      "Non-trainable params: 4,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GN = Get_GN_train()\n",
    "GN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Image(path):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_Loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 回傳兩個\n",
    "def Adversial_Loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Constrained_Loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-b2c0b0bc57b0>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b2c0b0bc57b0>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    2:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## 兩種模式\n",
    "def GN_Loss(mode):\n",
    "    switcher = {\n",
    "        1: \n",
    "        2: \n",
    "    }\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DN_Loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequence_Data(path, batch_size):\n",
    "    while True:\n",
    "        # 宣告資料夾位置\n",
    "        path_ori = os.path.join(path, \"Original\")\n",
    "        path_cmp = os.path.join(path, \"Compressed\")\n",
    "        \n",
    "        # 取得資料 '檔案名稱'\n",
    "        original = os.listdir(path_ori)\n",
    "        compressed = os.listdir(path_cmp)\n",
    "        \n",
    "        # 檔案依照名稱排序，以利於同時在不同資料夾中取出相對應的資料\n",
    "        original.sort()\n",
    "        compressed.sort()\n",
    "        \n",
    "        cnt = 0\n",
    "        X =[]  \n",
    "        Y =[]  \n",
    "        for image in original:  \n",
    "            # create Numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x = cv2.imread(\"{}/{}\".format(path_ori, image))\n",
    "            y = cv2.imread(\"{}/{}\".format(path_cmp, image))\n",
    "            X.append(x)  \n",
    "            Y.append(y)  \n",
    "            \n",
    "            cnt += 1\n",
    "            if cnt==batch_size:  \n",
    "                cnt = 0\n",
    "                yield (np.asarray(X), np.asarray(Y))  \n",
    "                X = []  \n",
    "                Y = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 8s 3s/step - loss: 8703.6793 - acc: 0.0055 - val_loss: 8622.2064 - val_acc: 0.0216\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8620.7558 - acc: 0.0022 - val_loss: 8453.4237 - val_acc: 0.0579\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8488.9021 - acc: 0.0227 - val_loss: 8516.2135 - val_acc: 0.0568\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8445.7533 - acc: 0.0503 - val_loss: 8499.8607 - val_acc: 0.0343\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9927 - acc: 0.0561 - val_loss: 8449.4099 - val_acc: 0.0273\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9423 - acc: 0.0565 - val_loss: 8445.7418 - val_acc: 0.0334\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9244 - acc: 0.0565 - val_loss: 8444.2625 - val_acc: 0.0434\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9229 - acc: 0.0564 - val_loss: 8443.9748 - val_acc: 0.0521\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9219 - acc: 0.0563 - val_loss: 8443.9240 - val_acc: 0.0555\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9214 - acc: 0.0562 - val_loss: 8443.9213 - val_acc: 0.0562\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9213 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9212 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9212 - val_acc: 0.0562\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9209 - val_acc: 0.0562\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9211 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9208 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9208 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9208 - val_acc: 0.0562\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9207 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9206 - acc: 0.0562 - val_loss: 8443.9207 - val_acc: 0.0562\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9206 - acc: 0.0562 - val_loss: 8443.9206 - val_acc: 0.0562\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9205 - acc: 0.0562 - val_loss: 8443.9205 - val_acc: 0.0562\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9204 - acc: 0.0562 - val_loss: 8443.9205 - val_acc: 0.0562\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 8443.9203 - acc: 0.0562 - val_loss: 8443.9204 - val_acc: 0.0562\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9202 - acc: 0.0562 - val_loss: 8443.9203 - val_acc: 0.0562\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9202 - acc: 0.0562 - val_loss: 8443.9202 - val_acc: 0.0562\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8443.9201 - acc: 0.0562 - val_loss: 8443.9202 - val_acc: 0.0562\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9200 - acc: 0.0562 - val_loss: 8443.9201 - val_acc: 0.0562\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8443.9200 - acc: 0.0562 - val_loss: 8443.9200 - val_acc: 0.0562\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8443.9199 - acc: 0.0562 - val_loss: 8443.9200 - val_acc: 0.0562\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8443.9199 - acc: 0.0562 - val_loss: 8443.9199 - val_acc: 0.0562\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9199 - val_acc: 0.0562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9199 - val_acc: 0.0562\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8443.9198 - acc: 0.0562 - val_loss: 8443.9198 - val_acc: 0.0562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f764cec5cc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 要先拿少量資料測試 ！！\n",
    "batch_size = 1\n",
    "\n",
    "# Step 1: 讀取訓練資料（受損 / 原圖）\n",
    "# path_train = \"../Dataset/Training_Data\"  ## 受損影像路徑\n",
    "# path_valid = \"../Dataset/Validation_Data\"  ## 原圖影像路徑\n",
    "path_train = \"../Dataset/test\"  \n",
    "path_valid = \"../Dataset/test\"  \n",
    "\n",
    "\n",
    "# Step 2: 讀取 Models\n",
    "GN = Get_GN_train()\n",
    "# DN = Get_DN_train()\n",
    "\n",
    "\n",
    "# Step 3: 先稍微訓練 Generative Network\n",
    "GN.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "GN.fit_generator(generator=Sequence_Data(path_train, batch_size), steps_per_epoch=int(3),\n",
    "                    epochs=50, workers=1, use_multiprocessing=True, #callbacks=[checkpoint], \n",
    "                    validation_data=Sequence_Data(path_valid, batch_size), validation_steps=int(3)) \n",
    "\n",
    "\n",
    "\n",
    "# Step 4: 加入 Discriminiative Network 一起訓練， 儲存權重\n",
    "\n",
    "\n",
    "# Step 5: 儲存 Final 權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
