{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import h5py                                                                                                                                                                                   \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%run Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequence_Data(path, batch_size):\n",
    "    while True:\n",
    "        # 宣告資料夾位置\n",
    "        path_ori = os.path.join(path, \"Original_pgm\")\n",
    "        path_dcmp = os.path.join(path, \"Decompressed\")\n",
    "        \n",
    "        # 取得資料 '檔案名稱'\n",
    "        original = os.listdir(path_ori)\n",
    "        decompressed = os.listdir(path_dcmp)\n",
    "        \n",
    "        # 檔案依照名稱排序，以利於同時在不同資料夾中取出相對應的資料\n",
    "        original.sort()\n",
    "        decompressed.sort()\n",
    "        \n",
    "        cnt = 0\n",
    "        X =[]  \n",
    "        Y =[]  \n",
    "        for image in original:  \n",
    "            # create Numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x = cv2.imread(\"{}/{}\".format(path_dcmp, image),0)\n",
    "            y = cv2.imread(\"{}/{}\".format(path_ori, image),0)\n",
    "            X.append(x)  \n",
    "            Y.append(y)  \n",
    "            \n",
    "            cnt += 1\n",
    "            if cnt==batch_size: \n",
    "                Xb = np.asarray(X)\n",
    "                Yb = np.asarray(Y)\n",
    "                cnt = 0\n",
    "                yield (Xb.reshape(Xb.shape[0],64,64,1), Yb.reshape(Yb.shape[0],64,64,1))  \n",
    "                X = []  \n",
    "                Y = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0105 08:24:36.486299 140032793577216 deprecation.py:506] From /home/mj/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6917/32000 [=====>........................] - ETA: 12:56 - loss: 8651.1972 - acc: 4.0474e-04"
     ]
    }
   ],
   "source": [
    "## 要先拿少量資料測試 ！！\n",
    "batch_size = 1\n",
    "\n",
    "# Step 1: 讀取訓練資料（受損 / 原圖）\n",
    "path_train = \"../../Dataset/Training_Data\"  ## 受損影像路徑\n",
    "path_valid = \"../../Dataset/Validation_Data\"  ## 原圖影像路徑\n",
    "img_test = \"/home/mj/HardDisk/Github/Image_Compressor/Dataset/Training_Data/Original_pgm/00006458.pgm\"\n",
    "img_test = cv2.imread(img_test, 0).reshape(1,64,64,1)\n",
    "# Step 2: 讀取 Models\n",
    "GN  = Get_GN_train()\n",
    "# DN  = Get_DN_train()\n",
    "# GDN = Get_GD_Stacked(GN, DN)\n",
    "\n",
    "# Step 3: 初始化參數配置\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, decay=8e-8)\n",
    "GN.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "# DN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# GDN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#\n",
    "filepath=\"../../Model/weights-improvement-{epoch:03d}-{val_acc:.3f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "\n",
    "# Step : 先稍微訓練 Generative Network\n",
    "for i in range(5):\n",
    "    GN.fit_generator(generator=Sequence_Data(path_train, batch_size), steps_per_epoch=int(32000),\n",
    "                        epochs=1, use_multiprocessing=True, #callbacks=[checkpoint], #workers=20\n",
    "                        validation_data=Sequence_Data(path_valid, batch_size), validation_steps=int(4000))\n",
    "    \n",
    "    result = cv2.convertScaleAbs(GN.predict(img_test))\n",
    "    print(result.shape)\n",
    "    cv2.imshow(\"Img\", result.reshape(64,64,1))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "#     cv2.imwrite(\"/home/mj/HardDisk/Github/Image_Compressor/Model/Result_{}.png\".format(1), result)\n",
    "    \n",
    "\n",
    "# GDN.fit_generator(generator=Sequence_Data(path_train, batch_size), steps_per_epoch=int(16000),\n",
    "#                     epochs=1, use_multiprocessing=True, #callbacks=[checkpoint], workers=20\n",
    "#                     validation_data=Sequence_Data(path_valid, batch_size), validation_steps=int(4000))\n",
    "\n",
    "# Step : 加入 Discriminiative Network 一起訓練， 儲存權重\n",
    "\n",
    "# Step : 儲存 Final 權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
