{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import h5py                                                                                                                                                                                   \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%run Models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sequence_Data(path, batch_size):\n",
    "    while True:\n",
    "        # 宣告資料夾位置\n",
    "        path_ori = os.path.join(path, \"Original_pgm\")\n",
    "        path_dcmp = os.path.join(path, \"Decompressed\")\n",
    "        \n",
    "        # 取得資料 '檔案名稱'\n",
    "        original = os.listdir(path_ori)\n",
    "        decompressed = os.listdir(path_dcmp)\n",
    "        \n",
    "        # 檔案依照名稱排序，以利於同時在不同資料夾中取出相對應的資料\n",
    "        original.sort()\n",
    "        decompressed.sort()\n",
    "        \n",
    "        cnt = 0\n",
    "        X =[]  \n",
    "        Y =[]  \n",
    "        for image in original:  \n",
    "            # create Numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x = cv2.imread(\"{}/{}\".format(path_dcmp, image),0)\n",
    "            y = cv2.imread(\"{}/{}\".format(path_ori, image),0)\n",
    "            X.append(x)  \n",
    "            Y.append(y)  \n",
    "            \n",
    "            cnt += 1\n",
    "            if cnt==batch_size: \n",
    "                Xb = np.asarray(X)\n",
    "                Yb = np.asarray(Y)\n",
    "                cnt = 0\n",
    "                yield (Xb.reshape(Xb.shape[0],64,64,1), Yb.reshape(Yb.shape[0],64,64,1))  \n",
    "                X = []  \n",
    "                Y = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 281s 35ms/step - loss: 11222.0171 - acc: 3.6627e-04 - val_loss: 15993.6741 - val_acc: 2.7515e-04\n",
      "(1, 64, 64, 1)\n",
      " 205/8000 [..............................] - ETA: 6:48 - loss: 3678.1634 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "0## 要先拿少量資料測試 ！！\n",
    "batch_size = 1\n",
    "\n",
    "# Step 1: 讀取訓練資料（受損 / 原圖）\n",
    "path_train = \"../../Dataset/Training_Data\"  ## 受損影像路徑\n",
    "path_valid = \"../../Dataset/Validation_Data\"  ## 原圖影像路徑\n",
    "img_test = \"/home/mj/HardDisk/Github/Image_Compressor/Dataset/Training_Data/Original_pgm/00006458.pgm\"\n",
    "img_test = cv2.imread(img_test, 0).reshape(1,64,64,1)\n",
    "# Step 2: 讀取 Models\n",
    "GN  = Get_GN_train()\n",
    "# DN  = Get_DN_train()\n",
    "# GDN = Get_GD_Stacked(GN, DN)\n",
    "\n",
    "# Step 3: 初始化參數配置\n",
    "optimizer = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, decay=8e-8)\n",
    "GN.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "# DN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# GDN.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#\n",
    "filepath=\"../../Model/weights-improvement-{epoch:03d}-{val_acc:.3f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "\n",
    "# Step : 先稍微訓練 Generative Network\n",
    "for i in range(5):\n",
    "    GN.fit_generator(generator=Sequence_Data(path_train, batch_size), steps_per_epoch=int(8000),\n",
    "                        epochs=1, use_multiprocessing=True, #callbacks=[checkpoint], #workers=20\n",
    "                        validation_data=Sequence_Data(path_valid, batch_size), validation_steps=int(4000))\n",
    "    \n",
    "    result = cv2.convertScaleAbs(GN.predict(img_test))\n",
    "    print(result.shape)\n",
    "    cv2.imshow(\"Img\", result.reshape(64,64,1))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "#     cv2.imwrite(\"/home/mj/HardDisk/Github/Image_Compressor/Model/Result_{}.png\".format(1), result)\n",
    "    \n",
    "\n",
    "# GDN.fit_generator(generator=Sequence_Data(path_train, batch_size), steps_per_epoch=int(16000),\n",
    "#                     epochs=1, use_multiprocessing=True, #callbacks=[checkpoint], workers=20\n",
    "#                     validation_data=Sequence_Data(path_valid, batch_size), validation_steps=int(4000))\n",
    "\n",
    "# Step : 加入 Discriminiative Network 一起訓練， 儲存權重\n",
    "\n",
    "# Step : 儲存 Final 權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [5, 6]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = np.asarray([[1.1,1.5],[5,6.4]])\n",
    "cvuint8 = cv2.convertScaleAbs(image)\n",
    "cvuint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function imread> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-be55ec50a410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function imread> returned NULL without setting an error"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
